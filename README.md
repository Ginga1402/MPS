# 🧠 Model Context Protocol (MCP)

> An open-source standard to seamlessly connect Large Language Models (LLMs) with the external world — databases, APIs, services, and more.

---

## 🌐 What is MCP?

**Model Context Protocol (MCP)** is a new open-source protocol designed to empower LLMs by enabling them to interface with external tools, services, and data sources. Acting as a **translator layer**, MCP allows models to interact with APIs, databases, and other services in a standardized, extensible, and scalable way.

---

## 🚨 The Problem

LLMs alone can't execute real-world tasks — they only generate text. To build powerful AI assistants, we need to integrate them with tools like:

- Email services
- Search APIs
- Databases
- Custom scripts

But integrating multiple tools is hard. APIs vary widely, maintenance is a headache, and scalability is painful.

---

## ✅ MCP as a Solution

MCP provides a **standardized interface** that abstracts away the complexities of tool integration. Similar to how REST standardized web services, MCP standardizes how LLMs talk to tools — making integration cleaner, easier, and future-proof.

---

## 🔮 Why MCP?

MCP helps you build agents and complex workflows on top of LLMs. LLMs frequently need to integrate with data and tools, and MCP provides:

1. A growing list of pre-built integrations that your LLM can directly plug into
2. The flexibility to switch between LLM providers and vendors
3. Best practices for securing your data within your infrastructure

---



## 🧩 Architecture & Components

| Component     | Description |
|---------------|-------------|
| **MCP Client** | The LLM-facing component. Can reside in chat apps, dev tools, or assistants. |
| **MCP Server** | Built by service providers. Translates service functionality (e.g., database queries, API calls) into a format LLMs can understand. |
| **MCP Protocol** | The two-way transport layer enabling secure, structured communication between client and server. |
| **Service** | The actual tool or external resource being accessed (e.g., Weather API, SQL DB). |

---



## 🔁 How It Works (Flow Example)

<img src="https://github.com/user-attachments/assets/fffe5e30-be96-4f33-bf01-640d107c1d6d" width="400" />


1. User sends query via an MCP host (e.g., chat app).
2. MCP Client identifies the need for an external tool.
3. MCP Server advertises available tools.
4. LLM decides which tool(s) to use and instructs the client.
5. Client sends request to relevant MCP Server.
6. Server connects to the external service and retrieves data.
7. Response flows back to the LLM for final output generation.

---

## ✨ Key Benefits

- ✅ **Simplified Tool Integration**
- 🚀 **Extended LLM Capabilities**
- 🛠️ **Scalable, Maintainable Architecture**
- 🤝 **Standardized Communication Layer**
- 💡 **Fosters Innovation for AI App Developers**


---

## 🛠️ Tech Stack Used

- **[Python](https://www.python.org/)** - Python forms the backbone of CodeBuddy, providing robust support for integration with various libraries and frameworks.
- **[Langchain](https://github.com/hwchase17/langchain)** - LangChain is a framework designed to simplify the creation of applications using large language models.
- **[Ollama](https://ollama.com/)** - It provides a simple API for creating, running, and managing models, as well as a library of pre-built models that can be easily used in a variety of applications.
- **[langchain-mcp-adapters](https://github.com/langchain-ai/langchain-mcp-adapters)** - This library provides a lightweight wrapper that makes Anthropic Model Context Protocol (MCP) tools compatible with LangChain and LangGraph. 

---


## 🧩  Files Overview

| File   | Description|
|---------------|-------------|
| **client.py** | A basic MCP client interacting only with a single mathserver. |
| **mathserver.py** | An MCP server that exposes simple math operations (e.g., addition, multiplication). |
| **weatherserver.py** | An MCP server simulating weather data responses. |
| **multiclient.py** |A multi-client setup where the MCP client can connect to both the math and weather servers. |

---


## 🔄 How It Works

1. The client.py script simulates an AI assistant (or LLM) interacting with the Math MCP Server only.

2. The multiclient.py script demonstrates a more advanced use-case where the MCP client discovers and uses tools from multiple servers (Math + Weather).

3. mathserver.py and weatherserver.py expose capabilities that can be consumed by MCP clients.



## 🚀 Running the Demo

1. Start the Servers:

   ```bash
   python mathserver.py
   python weatherserver.py
   
   ```

2. Run Single-Client Demo:

    ```bash
    python client.py
   
   ```  

3. Run Multi-Client Demo:

     ```bash
    python multiclient.py

   ```   

---

## 🚀 Get Involved
Contributions are welcome! If you have suggestions or would like to enhance this project, please fork the repository and submit a pull request.

Interested in contributing to MCP? Stay tuned for:

- Contribution guidelines
- Roadmap
- Issue templates

Feel free to ⭐️ the repo and join the discussion!

---

## License
This project is licensed under the MIT License. See the `LICENSE` file for more details.

