#### Harnessing LLMs and Generative AI for Fluid Conversations and Context-Aware Responses

# Aira âœ¨: Your Intelligent Voice Assistant


## Overview


This project introduces a cutting-edge voice assistant powered by Large Language Models (LLMs) and Generative AI, designed to revolutionize user interaction. The application allows seamless conversation with the assistant, which not only answers a wide range of queries but also remembers the context of previous interactions. This memory feature enables the assistant to provide more accurate and context-aware responses over time. By leveraging advanced query handling and the generative capabilities of AI, this voice assistant is ideal for use cases such as customer support, personal assistance, and interactive education, offering a sophisticated, intelligent, and user-friendly experience.

AIRA, our voice assistant, is named for its deep meanings: "the beginning," "the principle," and "the breath of life." This reflects our aim to innovate from the ground up, grounded in core AI principles, and to bring fresh, intuitive interactions to users

## Tech Stack Used

The following technologies and libraries were used in the development of this application:

[Python](https://www.python.org/): Programming language used for the implementation.

[Langchain](https://www.langchain.com/): LangChain is a framework designed to simplify the creation of applications using large language models.

[Ollama](https://ollama.com/): It provides a simple API for creating, running, and managing models, as well as a library of pre-built models that can be easily used in a
variety of applications.

Model Used: [Mistral 7B](https://huggingface.co/mistralai/Mistral-7B-v0.1)  is a language model developed by Mistral, an organization specializing in AI and machine learning technologies. It's part of the Mistral family of models and has around 7 billion parameters.

[Whisper](https://github.com/openai/whisper) is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multitasking model that can perform multilingual speech recognition, speech translation, and language identification.


## Getting Started

To get started with the Open-source AI equipped voice assistant, follow these steps:

1. Clone the repository
```py
git clone https://github.com/Ginga1402/Talk_with_AI
```
2. Install the required dependencies:

```py
pip install -r requirements.txt
```

3. Run the Whisper API :

```py
python run whisper_api.py
```


4. Run the Voice Assistant application 
```py
python run main.py
```

## Usage
The application features an intuitive command-line interface. Simply speak your query, and the assistant will generate and vocalize a response.

## Contributing
Contributions to this project are welcome! If you have ideas for improvements, bug fixes, or new features, feel free to open an issue or submit a pull request.

## License
This project is licensed under the MIT License - see the LICENSE file for details.


